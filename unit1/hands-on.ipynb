{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "\n",
    "virtual_display = Display(visible=False, size=(1400, 900))\n",
    "virtual_display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "from huggingface_sb3 import load_from_hub, package_to_hub, push_to_hub\n",
    "from huggingface_hub import (\n",
    "    notebook_login,\n",
    ")\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "observation = env.reset()\n",
    "\n",
    "for _ in range(20):\n",
    "    action = env.action_space.sample()\n",
    "    print(action)\n",
    "\n",
    "    observation, reward, done, info = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        print('done.')\n",
    "        observation = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space shape: (8,)\n",
      "Sample observation:  [-0.8589128   1.241753    1.2944345  -0.01915429  0.07398096 -0.03286204\n",
      "  0.39541364 -0.06663246]\n",
      "Action space shape: 4\n",
      "Sample action:  0\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "print('Observation space shape:', env.observation_space.shape)\n",
    "print('Sample observation: ', env.observation_space.sample())\n",
    "\n",
    "print('Action space shape:', env.action_space.n)\n",
    "print('Sample action: ', env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\n",
    "    policy='MlpPolicy',\n",
    "    env=env,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    n_epochs=4,\n",
    "    gamma=0.999,\n",
    "    gae_lambda=0.98,\n",
    "    ent_coef=0.01,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | -91.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 1303     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 108         |\n",
      "|    ep_rew_mean          | -86.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1059        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011711956 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -0.00224    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 331         |\n",
      "|    n_updates            | 44          |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 726         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 116         |\n",
      "|    ep_rew_mean          | -83.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 947         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004848994 |\n",
      "|    clip_fraction        | 0.00281     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -0.00131    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 426         |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.00224    |\n",
      "|    value_loss           | 1.07e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 118         |\n",
      "|    ep_rew_mean          | -89.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 953         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006356204 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -0.00326    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 543         |\n",
      "|    n_updates            | 52          |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    value_loss           | 1.04e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 120        |\n",
      "|    ep_rew_mean          | -92.5      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 949        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00585526 |\n",
      "|    clip_fraction        | 0.0127     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.26      |\n",
      "|    explained_variance   | -0.0206    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 286        |\n",
      "|    n_updates            | 56         |\n",
      "|    policy_gradient_loss | -0.00402   |\n",
      "|    value_loss           | 1.24e+03   |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "model_name = \"ppo-lunarlander-v2\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
    "\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e47bff9b564ed3818eb4876c4a5cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "from huggingface_sb3 import package_to_hub\n",
    "\n",
    "repo_id = \"akghxhs55/ppo-lunarlander-v2\"\n",
    "\n",
    "env_id = \"LunarLander-v2\"\n",
    "\n",
    "eval_env = DummyVecEnv([lambda: gym.make(env_id)])\n",
    "\n",
    "\n",
    "model_architecture = \"PPO\"\n",
    "\n",
    "commit_message = \"initial commit\"\n",
    "\n",
    "package_to_hub(model=model,\n",
    "               model_name=model_name,\n",
    "               model_architecture=model_architecture,\n",
    "               env_id=env_id,\n",
    "               eval_env=eval_env,\n",
    "               repo_id=repo_id,\n",
    "               commit_message=commit_message,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "53fbb8a05076721312468b4aa51a591bafc98cb93e1b83b6d4d9c563a73c1d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
